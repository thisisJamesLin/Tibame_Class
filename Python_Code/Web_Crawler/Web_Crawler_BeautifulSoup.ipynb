{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "506a7efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.2.1-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.9.3 soupsieve-2.2.1\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "#          Install  package             #\n",
    "#########################################\n",
    "\n",
    "!pip install beautifulsoup4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f91d72ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Project\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "#            package             #\n",
    "##################################\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "##################################\n",
    "#         Start Project          #\n",
    "##################################\n",
    "\n",
    "print('Start Project')\n",
    "print('--'*10)\n",
    "##################################\n",
    "#            網頁擷取             #\n",
    "##################################\n",
    "Target_Address = fr'https://udn.com/news/breaknews/2'\n",
    "\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36 Edg/91.0.864.41'}\n",
    "\n",
    "response = requests.get(url = Target_Address , headers = headers)\n",
    "\n",
    "##################################\n",
    "#          解析網頁程式           #\n",
    "##################################\n",
    "\n",
    "soup = BeautifulSoup( response.text , 'html.parser' ) #解析成純文字，運用'html.parser'解析器\n",
    "\n",
    "            ##  Another Way ##\n",
    "            # soup = response.content.decode()       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28fdaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "037318d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "標題：被讚減少環境衝擊 哈利、梅根「決定不生第三胎」獲獎\n",
      "標題：南韓預估連5天單日確診逾千例 接種速度引憂心\n",
      "標題：東京奧運賽事以「無觀眾」進行 福島、北海道跟進\n",
      "標題：潛水員淡水外海清除廢棄漁網 失蹤三天仍未尋獲\n",
      "標題：新北今確診數8成與北市相關 江啟臣：雙北應區域聯防\n",
      "標題：警專姐批政府防疫文遭下架 國民黨團：噁心大人查水錶\n",
      "標題：因為分不到「這東西」 譚德塞：Delta變異株正獲得勝利\n",
      "標題：微解封霧煞煞 全台將開放景點看這裡\n",
      "標題：遊樂設施失控！遊客半空中「瘋狂旋轉」 驚悚畫面曝光\n",
      "標題：9款Android App 被發現會竊取用戶的Facebook密碼\n",
      "標題：陳其邁昨宣布水域活動不解禁 西子灣今卻現戲水人潮\n",
      "標題：高雄水電工脫口罩吃早餐被罰3千元  衛生局：不罰了\n",
      "標題：確診憂鬱人數增 護理師：在我面前說不想活 怎麼辦？\n",
      "標題：日職／王柏融代打選到保送 個人連7場上壘\n",
      "標題：地方如何拚施打速度？林右昌建議中央「雙軌制」\n",
      "標題：基隆新增台北職場接觸者確診 足跡搭國光、首都客運\n",
      "標題：離鄉背井更加「愛黨愛國」 在美留學陸生吐心聲\n",
      "標題：日照據點解封下周討論 照顧者怒了：現在才討論太慢\n",
      "標題：全島唯一「順時中」開放內用 花縣府：若有必要會調整\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "#       Homepage All Title       #\n",
    "##################################\n",
    "\n",
    "allTitle = soup.select( '.story-list__text h2 a' )[1:]\n",
    "for each_title in allTitle:\n",
    "    print('標題：' + each_title.text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f1afed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fb051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#          News Content          #\n",
    "##################################\n",
    "\n",
    "allTitle = soup.select( '.story-list__text h2 a' )[1:]\n",
    "\n",
    "for each_title in allTitle:\n",
    "    each_href = each_title['href']\n",
    "    \n",
    "    ##################################\n",
    "    #            網頁擷取             #\n",
    "    ##################################\n",
    "    \n",
    "    Target_News_Address = fr'https://udn.com{each_href}'\n",
    "    print(Target_News_Address)\n",
    "    response = requests.get( Target_News_Address )\n",
    "\n",
    "    ##################################\n",
    "    #          解析網頁程式           #\n",
    "    ##################################\n",
    "\n",
    "    soup = BeautifulSoup( response.text , 'html.parser' ) #解析成純文字，運用'html.parser'解析器\n",
    "    allContent = soup.select( '.article-content__editor p' )\n",
    "    \n",
    "\n",
    "    ##################################\n",
    "    #           資料前處理            #\n",
    "    ##################################\n",
    "    \n",
    "    allContent_Save = []\n",
    "    for paragraph in allContent :\n",
    "        \n",
    "        ##################################\n",
    "        #         前處理 Function         #\n",
    "        ##################################\n",
    "        def replace_all(tag, pre_dict):\n",
    "            \n",
    "            ##################################\n",
    "            #       排除文章最後的索引         #\n",
    "            ##################################\n",
    "            \n",
    "            excepts = ['延伸閱讀','本文授權', '【更多', '【2021']\n",
    "            \n",
    "            \n",
    "            text = \"\"\n",
    "            if tag.get_text() != \"\":\n",
    "                if sum([x in tag.get_text() for x in excepts]) != 0:\n",
    "                    pass\n",
    "\n",
    "                text += tag.get_text()\n",
    "             \n",
    "            ##################################\n",
    "            #          定義取代字典           #\n",
    "            ##################################\n",
    "            repalce_dict = {\n",
    "                            '<p>' : '' ,\n",
    "                            '</p>' : '' ,\n",
    "                            '</strong></a>' : ''\n",
    "                           } \n",
    "            \n",
    "            for i, j in pre_dict.items():\n",
    "                text = text.replace(i, j)\n",
    "            \n",
    "            return text\n",
    "        \n",
    "        \n",
    "        paragraph = replace_all(paragraph, repalce_dict)\n",
    "        \n",
    "        ##################################\n",
    "        #            設定時間             #\n",
    "        ##################################\n",
    "        \n",
    "        time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2914c2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03e6d06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
